{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59f20b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mtpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "font = {'family' : 'serif','weight' : 'ultralight','size'   : 14}\n",
    "mtpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d282057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Smooth121(x):\n",
    "    signal = x\n",
    "    length = len(signal)\n",
    "    output = np.zeros(length-2)\n",
    "    coef= np.array([1,2,1])\n",
    "    for i in range(length - 2):\n",
    "        output[i]= np.sum(signal[i:i+3] * coef / 4)\n",
    "    return output\n",
    "\n",
    "def Haar(ix,smooth=True,bins=20):\n",
    "    x=np.array(lis[ix][lis[ix].columns[1]])\n",
    "    t=np.array(lis[ix][lis[ix].columns[0]])\n",
    "\n",
    "    #Cálculo deltas\n",
    "    deltas_t=[]\n",
    "    epsilons=[]\n",
    "    for i in range(1,int(len(t)/2)+1):\n",
    "        deltas_t.append(t[i:]-t[:-i])\n",
    "    for i in range(1,len(deltas_t)+1):\n",
    "        epsilons.append(deltas_t[i-1][:-i]/(deltas_t[i-1][:-i]+deltas_t[i-1][i:]))\n",
    "    x=x[:-1];t=t[:-1]\n",
    "    \n",
    "    #Cálculo fluctuaciones\n",
    "    Hs=[]\n",
    "    delta_t=[]\n",
    "    ep_min=0.25\n",
    "    ep_max=1-ep_min\n",
    "    calib=2\n",
    "    counter=0\n",
    "    \n",
    "    for H in range(2,len(x)-1,2):\n",
    "        for start in range(len(x)-H-1):\n",
    "            int1=np.sum(x[start:start+int(H/2)]*deltas_t[0][start:start+int(H/2)]/deltas_t[int(H/2)-1][start])\n",
    "            int2=np.sum(x[start+int(H/2):start+H]*deltas_t[0][start+int(H/2):start+H]/deltas_t[int(H/2)-1][start+int(H/2)])\n",
    "            counter+=1\n",
    "            if ep_min<epsilons[int(H/2)-1][start] and epsilons[int(H/2)-1][start]<ep_max:\n",
    "                Hs.append((calib*(int2-int1))**2)\n",
    "                delta_t.append(deltas_t[int(H/2)-1][start]+deltas_t[int(H/2)-1][start+int(H/2)])\n",
    "    \n",
    "    #Paso a dataframes\n",
    "    data_df=pd.DataFrame(data={'delta t':delta_t , 'Hs': Hs})\n",
    "    data_sorted=data_df.sort_values('delta t',axis=0).reset_index(drop=True)\n",
    "\n",
    "    max_t=max(np.log10(data_sorted['delta t'])); min_t=min(np.log10(data_sorted['delta t']))\n",
    "    n_bins=int(((max_t)-(min_t))*bins); rango_int=(max_t-min_t)/n_bins; time=np.array([]); ave_values=np.array([]); upper=np.array([]); lower=np.array([]);\n",
    "    for i in range(n_bins):\n",
    "        interval=data_sorted[(i*rango_int+min_t<=np.log10(data_sorted['delta t']))&(np.log10(data_sorted['delta t'])<min_t+(i+1)*rango_int)]\n",
    "        time=np.append(time,((i*rango_int+min_t)+((i+1)*rango_int+min_t))/2)\n",
    "        ave_values=np.append(ave_values,np.sqrt(interval.mean()[1]))        ## Tomo el sqrt del <[2*(x1-x2)]^2> ...\n",
    "        upper=np.append(upper,np.sqrt(interval.mean()[1]+interval.std()[1]/np.sqrt(len(interval))))\n",
    "        lower=np.append(lower,np.sqrt(interval.mean()[1]-interval.std()[1]/np.sqrt(len(interval))))\n",
    "        \n",
    "    if smooth==False:\n",
    "        smooth_val=ave_values\n",
    "    if smooth==True:\n",
    "        smooth_val=Smooth121(ave_values)\n",
    "        upper=Smooth121(upper)\n",
    "        lower=Smooth121(lower)\n",
    "        time=time[1:-1]\n",
    "    val_mask = np.isfinite(smooth_val)\n",
    "    \n",
    "    time=time[val_mask] #??\n",
    "    smooth_val=smooth_val[val_mask] #??\n",
    "    upper=upper[val_mask]\n",
    "    lower=lower[val_mask]\n",
    "\n",
    "    return time,smooth_val,upper,lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5a29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_file='EDC_DustFlux_25yr.xlsx'\n",
    "\n",
    "id_columns=['Name','Data id','Latitud','Longitud','Age units','Data units','Data length']\n",
    "id_data=pd.read_excel(dust_file,sheet_name=0,usecols=id_columns)\n",
    "df_data=pd.read_excel(dust_file,sheet_name=1,skiprows=1)\n",
    "\n",
    "#SEPARAR COLUMNAS\n",
    "columns=df_data.size/len(df_data) ;lis=[];new_length=np.array([])\n",
    "\n",
    "for i in range(int(columns)):\n",
    "    if (i+1)%2==1: \n",
    "        dupla=df_data[[df_data.columns[i],df_data.columns[i+1]]].dropna() \n",
    "        dupla.index=[j for j in range(0, len(dupla))] \n",
    "        lis.append(dupla)\n",
    "        new_length=np.append(new_length,np.shape(dupla)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62d69cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[time1,val1,upper1,lower1]=Haar(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6437e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.DataFrame(time1,columns=['Time'])\n",
    "v=pd.DataFrame(val1,columns=['Values'])\n",
    "u=pd.DataFrame(upper1,columns=['Upper'])\n",
    "l=pd.DataFrame(lower1,columns=['Lower'])\n",
    "\n",
    "haar_data=pd.concat([t,v,u,l],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aa7075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_data.to_excel('Haar4cluster results1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9b114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
